# Dashboard para obter estat√≠sticas e definir a normaliza√ß√£o de dados

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image

# -------------------------
# Configura√ß√µes
# -------------------------
DATA_PATH = "/content/drive/MyDrive/dados-CLICKBUS/df_t_MODIFICADO.csv"
LOGO_PATH = "/content/drive/MyDrive/dados-CLICKBUS/ClickBus_logo.png"

st.set_page_config(layout="wide", page_title="Dashboard Estat√≠sticas Originais")

# -------------------------
# T√≠tulo do Dashboard e Logotipo
# -------------------------

col_title, col_logo = st.columns([0.8, 0.2])

with col_title:
    st.title("üìä Estat√≠stica Inicial para Normaliza√ß√£o dos Dados")
    
with col_logo:
    try:
        image = Image.open(LOGO_PATH)
        st.image(image, width=150)
    except FileNotFoundError:
        st.error("Erro: Arquivo do logo n√£o encontrado. Verifique o caminho.")

# -------------------------
# Carregamento dos dados
# -------------------------
@st.cache_data
def load_data():
    df = pd.read_csv(DATA_PATH, low_memory=True)
    return df

try:
    df = load_data()
except Exception as e:
    st.error(f"Erro ao carregar o arquivo: {e}")
    st.stop()

# -------------------------
# Estat√≠sticas descritivas
# -------------------------
st.header("üìã Estat√≠sticas Descritivas ‚Äî Vari√°veis Num√©ricas")

numeric_cols = df.select_dtypes(include=["int64", "float64"]).columns.tolist()

if numeric_cols:
    desc = df[numeric_cols].describe().T
    desc["mediana"] = df[numeric_cols].median()
    desc["n_valores_unicos"] = df[numeric_cols].nunique()

    # Renomeando para Portugu√™s (PT-BR)
    desc = desc.rename(columns={
        "count": "Contagem (n)",
        "mean": "M√©dia",
        "std": "Desvio padr√£o",
        "min": "M√≠nimo",
        "25%": "1¬∫ Quartil (Q1)",
        "50%": "2¬∫ Quartil (Mediana/Q2)",
        "75%": "3¬∫ Quartil (Q3)",
        "max": "M√°ximo"
    })

    st.dataframe(desc)

    st.markdown("""
    **Explica√ß√£o das estat√≠sticas apresentadas:**
    - **Contagem (n):** quantidade de registros n√£o nulos considerados no c√°lculo.
    - **M√©dia:** soma de todos os valores dividida pela quantidade (tend√™ncia central).
    - **Desvio padr√£o:** medida de dispers√£o que indica quanto os valores variam em torno da m√©dia.
    - **M√≠nimo / M√°ximo:** menor e maior valor encontrado na coluna.
    - **Quartis (Q1, Q2, Q3):** valores que dividem os dados em 4 partes iguais.
        - Q1: 25% dos valores s√£o menores ou iguais.
        - Q2: Mediana (50% dos valores abaixo e 50% acima).
        - Q3: 75% dos valores s√£o menores ou iguais.
    - **Mediana:** valor central dos dados ordenados, mais robusto a outliers que a m√©dia.
    - **Valores √∫nicos:** quantidade de valores distintos encontrados na coluna.
    """)

# -------------------------
# Missing values
# -------------------------
st.header("‚ùì An√°lise de Valores Ausentes (Missing)")

missing = df.isna().sum().rename("Quantidade de valores ausentes").to_frame()
missing["% de valores ausentes"] = (missing["Quantidade de valores ausentes"] / len(df) * 100).round(2)
st.dataframe(missing)

if missing["Quantidade de valores ausentes"].sum() == 0:
    st.success("‚úÖ N√£o foram encontrados valores ausentes expl√≠citos (NaN).")
else:
    st.warning("‚ö†Ô∏è Existem valores ausentes (NaN). Devem ser avaliados com o time de neg√≥cio antes de qualquer imputa√ß√£o.")

st.markdown("""
**O que foi considerado:** - Valores nulos expl√≠citos (`NaN`) foram identificados e contabilizados.
- Valores "disfar√ßados" (como `0` ou `"NA"`) **n√£o foram considerados** como missing aqui, pois podem ser leg√≠timos para o neg√≥cio.
""")

# -------------------------
# Outliers (IQR)
# -------------------------
st.header("üìà An√°lise de Outliers (M√©todo do IQR)")

def detect_outliers(series):
    s = pd.to_numeric(series, errors="coerce").dropna()
    if len(s) < 4:
        return 0
    q1, q3 = s.quantile([0.25, 0.75])
    iqr = q3 - q1
    return int(((s < (q1 - 1.5 * iqr)) | (s > (q3 + 1.5 * iqr))).sum())

outlier_summary = {col: detect_outliers(df[col]) for col in numeric_cols}
out_df = pd.DataFrame.from_dict(outlier_summary, orient="index", columns=["Qtde de outliers (IQR)"])
st.dataframe(out_df)

if out_df["Qtde de outliers (IQR)"].sum() == 0:
    st.success("‚úÖ Nenhum outlier identificado pelas regras de IQR.")
else:
    st.info("‚ÑπÔ∏è Foram identificados outliers estat√≠sticos. No entanto, no contexto de neg√≥cio (passagens/tickets), valores extremos podem ser leg√≠timos e **n√£o devem ser tratados automaticamente**.")

st.markdown("""
**O que foi considerado:** - **Outliers pelo m√©todo do IQR (Interquartile Range):** - Intervalo interquart√≠lico (IQR) = Q3 - Q1
  - Valores abaixo de **Q1 - 1,5√óIQR** ou acima de **Q3 + 1,5√óIQR** s√£o considerados outliers.
- Esse m√©todo √© estat√≠stico e **n√£o avalia o contexto de neg√≥cio**.
""")

# -------------------------
# Categorias (Paretto)
# -------------------------
st.header("üè∑ An√°lise de Categorias ‚Äî Paretto (80/20)")

cat_cols = df.select_dtypes(include=["object"]).columns.tolist()
selected_col = st.selectbox("Selecione uma coluna categ√≥rica:", cat_cols)

def paretto_table(df, col):
    freq = df[col].value_counts(dropna=False).reset_index()
    freq.columns = [col, "Frequ√™ncia"]
    freq["%"] = freq["Frequ√™ncia"] / freq["Frequ√™ncia"].sum() * 100
    freq["% acumulado"] = freq["%"].cumsum()
    return freq

if selected_col:
    freq = paretto_table(df, selected_col)
    st.dataframe(freq.head(20))

    fig, ax = plt.subplots()
    ax.bar(freq[selected_col].astype(str).head(20), freq["%"].head(20))
    ax.plot(freq[selected_col].astype(str).head(20),
            freq["% acumulado"].head(20), color="red", marker="o")
    ax.axhline(80, color="green", linestyle="--")
    plt.xticks(rotation=90)
    st.pyplot(fig)

    if (freq["% acumulado"] >= 80).idxmax() < len(freq) / 2:
        st.success(f"‚úÖ A coluna `{selected_col}` segue a regra de Paretto: poucos valores concentram a maioria dos registros.")
    else:
        st.info(f"‚ÑπÔ∏è A coluna `{selected_col}` apresenta distribui√ß√£o mais equilibrada entre categorias.")

st.markdown("""
**O que foi considerado:** - **Princ√≠pio de Paretto (80/20):** aproximadamente 80% dos registros costumam estar concentrados em 20% das categorias.
- Essa an√°lise ajuda a identificar colunas dominadas por poucos valores frequentes.
""")

# -------------------------
# Conclus√£o final
# -------------------------
st.header("üìù Conclus√£o Geral")

conclusions = []
if missing["Quantidade de valores ausentes"].sum() == 0:
    conclusions.append("N√£o foram encontrados valores ausentes expl√≠citos (NaN).")
else:
    conclusions.append("Foram encontrados valores ausentes (NaN). Devem ser avaliados com o time de neg√≥cio.")

if out_df["Qtde de outliers (IQR)"].sum() == 0:
    conclusions.append("Nenhum outlier estat√≠stico identificado.")
else:
    conclusions.append("Foram identificados outliers estat√≠sticos, mas no contexto de neg√≥cio podem ser leg√≠timos.")

conclusions.append("Valores categ√≥ricos foram analisados via Paretto (80/20). Algumas colunas apresentam forte concentra√ß√£o, outras n√£o.")

st.write("**Resumo:**")
for c in conclusions:
    st.write("- " + c)

st.info("üëâ Conclus√£o: **N√£o realizar tratamento autom√°tico de missings/outliers. Avaliar cada caso com base no contexto do neg√≥cio e na relev√¢ncia da vari√°vel para o modelo preditivo.**")